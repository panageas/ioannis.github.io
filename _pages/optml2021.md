---
permalink: /optml2021/
title: "CS 295 - Optimization for Machine Learning"
excerpt: "optml2021"
author_profile: true
redirect_from: 
  - /optml2021
  - /optml2021.md
---

Below we will be posting slides and lecture notes for the class. The syllabus can be found [here](https://panageas.github.io/_pages/syllabus_optml2021.pdf).

[Lecture 1 slides](https://panageas.github.io/optmlslides/L01 GD.pdf): Definitions and Gradient Descent <br/>
[Lecture 2 slides](https://panageas.github.io/optmlslides/L02 GD.pdf): Gradient Descent (cont.) <br/>
[Lecture 3 slides](https://panageas.github.io/optmlslides/L03 SGD.pdf): Stochastic Gradient Descent <br/>
[Lecture 4 slides](https://panageas.github.io/optmlslides/L04 SGD(examples).pdf): Stochastic Gradient Descent (examples) <br/>
[Lecture 5 slides](https://panageas.github.io/optmlslides/L05 Online.pdf): Intro to Online optimization and Online Learning <br/>
[Lecture 6 slides](https://panageas.github.io/optmlslides/L06 Online(partb).pdf): Online optimization and Online Learning (cont.) <br/>
[Lecture 7 slides](https://panageas.github.io/optmlslides/L07 Nesterov.pdf): Accelerated Methods <br/>
[Lecture 8 slides](https://panageas.github.io/optmlslides/L08 non-convex.pdf): Intro to non-convex optimization <br/>
[Lecture 9 slides](https://panageas.github.io/optmlslides/L09 non-convex.pdf): Non-convex optimization: GD + noise avoids saddles <br/>
