---
permalink: /
title: "Welcome"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /welcome
  - /welcome.html
---
<br/>

About Me
======
<span style="color:#ff0000">I will be moving </span> to [UC Irvine](https://uci.edu/) as an Assistant Professor in the department of [Computer Science](https://www.cs.uci.edu/).
I am an Assistant Professor in [Information Systems](https://istd.sutd.edu.sg/) at [SUTD](https://www.sutd.edu.sg/). Before that I was a MIT Postdoctoral Fellow working with [Costis Daskalakis](http://people.csail.mit.edu/costis/). I obtained my PhD in [Algorithms, Combinatorics, and Optimization (ACO)](https://www.aco.gatech.edu/) at [Georgia Tech](https://www.gatech.edu/), advised by [Prasad Tetali](http://people.math.gatech.edu/~tetali/). At Georgia Tech, I also obtained a MSc in Mathematics. I did my undergrad studies in [National Technical University of Athens](https://www.ntua.gr/en/). <br/>

Here are my [Google Scholar](https://scholar.google.com/citations?user=5NiFWuwAAAAJ&hl=en) and my [dblp](https://dblp.org/pers/hd/p/Panageas:Ioannis) profiles. <br/>

Interests
======
I am interested in theory of computation and its interface with optimization, dynamical systems, probability and statistics, machine learning and their applications to game theory, evolution and dynamics on networks. <br/>
Here is my [CV](https://panageas.github.io/files/panageascv_2020feb.pdf).

Selected Publications 
======
<br/>
[[Depth-Width Trade-offs for ReLU Networks via Sharkovsky's Theorem.](https://arxiv.org/abs/1912.04378)] 
_<font color="red">ICLR 2020 (spotlight), [[MIFODS Talk](https://www.youtube.com/watch?v=HNQ204BmOQ8)] <br/>
[[Regression from Dependent Observations.](https://arxiv.org/abs/1905.03353)] _<font color="red"> STOC 2019 </font>_  <br/>
First-order Methods Almost Always Avoid Saddle Points. <br/>
_<font color="red"> Math. Programming 2019, issue on non-convex optimization for statistical learning. </font>_ [[Arxiv](https://arxiv.org/abs/1710.07406)] <br/>
The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization.<br/>
_<font color="red">NeurIPS 2018</font>_ [[Arxiv](https://arxiv.org/abs/1807.03907)] <br/>
Multiplicative Weights Update with Constant step-size in Congestion Games: Convergence, Limit Cycles and Chaos. <br/>
 _<font color="red">NeurIPS 2017 (spotlight)</font>_ [[Arxiv](https://arxiv.org/abs/1703.01138)], [[Video](https://www.youtube.com/watch?v=KlYaUlcVooo&feature=youtu.be)] <br/>

Teaching
======
[Optimization for Machine Learning, Spring 2020](https://panageas.github.io/optimizationforML) <br/>
Introduction to Algorithms, Fall 2019 <br/>
Introduction to Algorithms, Fall 2018 <br/>

Students 
======
[Sai Ganesh Nagarajan](https://sites.google.com/view/sgnagarajan/home) <br/>

Postdocs
======
[Xiao Wang](https://xiiaowang.github.io/) 

Committees 
======
Conference on Economics and Computation (<b>EC</b>) 2019, 2020 <br/>
Neural Information Processing and Systems (<b>NeurIPS</b>) 2019 <br/>
International Conference on Machine Learning (<b>ICML</b>) 2019 <br/>
AAAI Conference on Artificial Intelligence (<b>AAAI</b>) 2020 <br/>
Conference on Web and Internet Economics (<b>WINE</b>) 2019



